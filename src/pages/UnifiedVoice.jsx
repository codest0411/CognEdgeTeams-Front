import { useState, useEffect, useRef } from 'react'
import { useAuth } from '../contexts/AuthContext'
import { supabase } from '../lib/supabaseClient'
import { useNavigate } from 'react-router-dom'

export default function UnifiedVoice() {
  const { user } = useAuth()
  const navigate = useNavigate()
  const [participants, setParticipants] = useState([])
  const [isMuted, setIsMuted] = useState(false)
  const [speakingUsers, setSpeakingUsers] = useState(new Set())
  const [isAudioEnabled, setIsAudioEnabled] = useState(false)
  const [audioError, setAudioError] = useState(null)
  
  // WebRTC and Audio refs
  const localStreamRef = useRef(null)
  const peerConnectionsRef = useRef({})
  const audioContextRef = useRef(null)
  const analyserRef = useRef(null)
  const voiceChannelRef = useRef(null)

  // FORCE everyone into the EXACT SAME voice session
  const VOICE_SESSION_ID = 'main-voice-session-2025'

  // Initialize audio on component mount
  useEffect(() => {
    initializeAudio()
    return () => {
      cleanup()
    }
  }, [])

  const initializeAudio = async () => {
    try {
      console.log('ğŸµ Initializing audio...')
      
      // Request microphone access
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      })
      
      localStreamRef.current = stream
      setIsAudioEnabled(true)
      setAudioError(null)
      
      // Set up voice activity detection
      setupVoiceActivityDetection(stream)
      
      console.log('âœ… Audio initialized successfully')
    } catch (error) {
      console.error('âŒ Audio initialization failed:', error)
      setAudioError('Microphone access denied. Please allow microphone access to join voice chat.')
      setIsAudioEnabled(false)
    }
  }

  const setupVoiceActivityDetection = (stream) => {
    try {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)()
      const analyser = audioContext.createAnalyser()
      const microphone = audioContext.createMediaStreamSource(stream)
      
      analyser.fftSize = 256
      microphone.connect(analyser)
      
      audioContextRef.current = audioContext
      analyserRef.current = analyser
      
      // Start voice activity detection
      detectVoiceActivity()
    } catch (error) {
      console.error('Voice activity detection setup failed:', error)
    }
  }

  const detectVoiceActivity = () => {
    if (!analyserRef.current) return
    
    const analyser = analyserRef.current
    const dataArray = new Uint8Array(analyser.frequencyBinCount)
    
    const checkAudio = () => {
      analyser.getByteFrequencyData(dataArray)
      
      // Calculate average volume
      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length
      
      // Update speaking status based on volume threshold
      const isSpeaking = average > 10 && !isMuted // Adjust threshold as needed
      
      setSpeakingUsers(prev => {
        const newSet = new Set(prev)
        if (isSpeaking) {
          newSet.add(user?.id)
        } else {
          newSet.delete(user?.id)
        }
        return newSet
      })
      
      // Continue monitoring
      if (isAudioEnabled) {
        requestAnimationFrame(checkAudio)
      }
    }
    
    checkAudio()
  }

  const cleanup = () => {
    // Stop local stream
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => track.stop())
    }
    
    // Close audio context
    if (audioContextRef.current) {
      audioContextRef.current.close()
    }
    
    // Close all peer connections
    Object.values(peerConnectionsRef.current).forEach(pc => pc.close())
    
    // Leave voice channel
    if (voiceChannelRef.current) {
      supabase.removeChannel(voiceChannelRef.current)
    }
  }

  useEffect(() => {
    if (!user) return

    console.log('ğŸ¤ FORCE JOINING voice session:', VOICE_SESSION_ID)

    // Create ONE shared channel that EVERYONE must join
    const sharedVoiceChannel = supabase.channel(VOICE_SESSION_ID)
    voiceChannelRef.current = sharedVoiceChannel

    // Track presence in the SAME session for ALL users
    sharedVoiceChannel
      .on('presence', { event: 'sync' }, () => {
        const state = sharedVoiceChannel.presenceState()
        const allUsers = []
        
        // Extract all users from presence state
        Object.keys(state).forEach(key => {
          const userPresences = state[key]
          userPresences.forEach(presence => {
            allUsers.push(presence)
          })
        })
        
        console.log('ğŸ‘¥ ALL USERS in UNIFIED session:', allUsers)
        setParticipants(allUsers)
        
        // Set up WebRTC connections for new users
        setupWebRTCConnections(allUsers)
      })
      .on('presence', { event: 'join' }, ({ newPresences }) => {
        console.log('âœ… User JOINED unified session:', newPresences)
        newPresences.forEach(presence => {
          if (presence.user_id !== user?.id) {
            createPeerConnection(presence.user_id)
          }
        })
      })
      .on('presence', { event: 'leave' }, ({ leftPresences }) => {
        console.log('âŒ User LEFT unified session:', leftPresences)
        leftPresences.forEach(presence => {
          closePeerConnection(presence.user_id)
        })
      })
      // WebRTC signaling
      .on('broadcast', { event: 'webrtc-offer' }, ({ payload }) => {
        handleWebRTCOffer(payload)
      })
      .on('broadcast', { event: 'webrtc-answer' }, ({ payload }) => {
        handleWebRTCAnswer(payload)
      })
      .on('broadcast', { event: 'webrtc-ice-candidate' }, ({ payload }) => {
        handleICECandidate(payload)
      })
      .subscribe(async (status) => {
        console.log('ğŸ“¡ Unified voice session status:', status)
        
        if (status === 'SUBSCRIBED') {
          // Add current user to the SAME session
          const userPresence = {
            user_id: user.id,
            user_name: user.user_metadata?.full_name || user.email.split('@')[0],
            user_email: user.email,
            is_muted: isMuted,
            joined_at: new Date().toISOString(),
            session_id: VOICE_SESSION_ID
          }
          
          await sharedVoiceChannel.track(userPresence)
          console.log('âœ… TRACKED in unified session:', userPresence)
        }
      })

    // Cleanup
    return () => {
      console.log('ğŸšª LEAVING unified voice session')
      sharedVoiceChannel.untrack()
      supabase.removeChannel(sharedVoiceChannel)
    }
  }, [user, isMuted])

  // WebRTC Functions
  const setupWebRTCConnections = (allUsers) => {
    allUsers.forEach(participant => {
      if (participant.user_id !== user?.id && !peerConnectionsRef.current[participant.user_id]) {
        createPeerConnection(participant.user_id)
      }
    })
  }

  const createPeerConnection = async (remoteUserId) => {
    try {
      const peerConnection = new RTCPeerConnection({
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' },
          { urls: 'stun:stun1.l.google.com:19302' }
        ]
      })

      peerConnectionsRef.current[remoteUserId] = peerConnection

      // Add local stream to peer connection
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => {
          peerConnection.addTrack(track, localStreamRef.current)
        })
      }

      // Handle incoming remote stream
      peerConnection.ontrack = (event) => {
        console.log('ğŸ“» Received remote audio stream from:', remoteUserId)
        const remoteAudio = new Audio()
        remoteAudio.srcObject = event.streams[0]
        remoteAudio.autoplay = true
        remoteAudio.volume = 1.0
        
        // Play the remote audio
        remoteAudio.play().catch(error => {
          console.error('Error playing remote audio:', error)
        })
      }

      // Handle ICE candidates
      peerConnection.onicecandidate = (event) => {
        if (event.candidate && voiceChannelRef.current) {
          voiceChannelRef.current.send({
            type: 'broadcast',
            event: 'webrtc-ice-candidate',
            payload: {
              candidate: event.candidate,
              from: user?.id,
              to: remoteUserId
            }
          })
        }
      }

      // Create and send offer
      const offer = await peerConnection.createOffer()
      await peerConnection.setLocalDescription(offer)

      if (voiceChannelRef.current) {
        voiceChannelRef.current.send({
          type: 'broadcast',
          event: 'webrtc-offer',
          payload: {
            offer: offer,
            from: user?.id,
            to: remoteUserId
          }
        })
      }

      console.log('ğŸ“ Created peer connection and sent offer to:', remoteUserId)
    } catch (error) {
      console.error('Error creating peer connection:', error)
    }
  }

  const handleWebRTCOffer = async ({ offer, from, to }) => {
    if (to !== user?.id) return

    try {
      const peerConnection = peerConnectionsRef.current[from] || new RTCPeerConnection({
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' },
          { urls: 'stun:stun1.l.google.com:19302' }
        ]
      })

      if (!peerConnectionsRef.current[from]) {
        peerConnectionsRef.current[from] = peerConnection

        // Add local stream
        if (localStreamRef.current) {
          localStreamRef.current.getTracks().forEach(track => {
            peerConnection.addTrack(track, localStreamRef.current)
          })
        }

        // Handle remote stream
        peerConnection.ontrack = (event) => {
          console.log('ğŸ“» Received remote audio stream from:', from)
          const remoteAudio = new Audio()
          remoteAudio.srcObject = event.streams[0]
          remoteAudio.autoplay = true
          remoteAudio.volume = 1.0
          remoteAudio.play().catch(error => {
            console.error('Error playing remote audio:', error)
          })
        }

        // Handle ICE candidates
        peerConnection.onicecandidate = (event) => {
          if (event.candidate && voiceChannelRef.current) {
            voiceChannelRef.current.send({
              type: 'broadcast',
              event: 'webrtc-ice-candidate',
              payload: {
                candidate: event.candidate,
                from: user?.id,
                to: from
              }
            })
          }
        }
      }

      await peerConnection.setRemoteDescription(offer)
      const answer = await peerConnection.createAnswer()
      await peerConnection.setLocalDescription(answer)

      if (voiceChannelRef.current) {
        voiceChannelRef.current.send({
          type: 'broadcast',
          event: 'webrtc-answer',
          payload: {
            answer: answer,
            from: user?.id,
            to: from
          }
        })
      }

      console.log('ğŸ“ Handled offer and sent answer to:', from)
    } catch (error) {
      console.error('Error handling WebRTC offer:', error)
    }
  }

  const handleWebRTCAnswer = async ({ answer, from, to }) => {
    if (to !== user?.id) return

    try {
      const peerConnection = peerConnectionsRef.current[from]
      if (peerConnection) {
        await peerConnection.setRemoteDescription(answer)
        console.log('ğŸ“ Handled answer from:', from)
      }
    } catch (error) {
      console.error('Error handling WebRTC answer:', error)
    }
  }

  const handleICECandidate = async ({ candidate, from, to }) => {
    if (to !== user?.id) return

    try {
      const peerConnection = peerConnectionsRef.current[from]
      if (peerConnection) {
        await peerConnection.addIceCandidate(candidate)
        console.log('ğŸ§Š Added ICE candidate from:', from)
      }
    } catch (error) {
      console.error('Error handling ICE candidate:', error)
    }
  }

  const closePeerConnection = (userId) => {
    const peerConnection = peerConnectionsRef.current[userId]
    if (peerConnection) {
      peerConnection.close()
      delete peerConnectionsRef.current[userId]
      console.log('ğŸ“ Closed peer connection with:', userId)
    }
  }

  const toggleMute = () => {
    const newMutedState = !isMuted
    setIsMuted(newMutedState)
    
    // Control the actual audio track
    if (localStreamRef.current) {
      const audioTrack = localStreamRef.current.getAudioTracks()[0]
      if (audioTrack) {
        audioTrack.enabled = !newMutedState
      }
    }
    
    console.log(newMutedState ? 'ğŸ”‡ Muted' : 'ğŸ”Š Unmuted')
  }

  const toggleUserMute = async (targetUserId, currentMuteState) => {
    // In a real implementation, this would send a mute/unmute command
    // For now, we'll simulate it by updating the participants state
    setParticipants(prevParticipants => 
      prevParticipants.map(participant => 
        participant.user_id === targetUserId 
          ? { ...participant, is_muted: !currentMuteState }
          : participant
      )
    )
    
    console.log(`${currentMuteState ? 'Unmuted' : 'Muted'} user: ${targetUserId}`)
    
    // In a real app, you would also broadcast this change to other users
    // via the Supabase channel or WebRTC signaling
  }

  const muteAllUsers = () => {
    setParticipants(prevParticipants => 
      prevParticipants.map(participant => ({ 
        ...participant, 
        is_muted: true 
      }))
    )
    setIsMuted(true)
    console.log('ğŸ”‡ Muted all users')
  }

  const unmuteAllUsers = () => {
    setParticipants(prevParticipants => 
      prevParticipants.map(participant => ({ 
        ...participant, 
        is_muted: false 
      }))
    )
    setIsMuted(false)
    console.log('ğŸ”Š Unmuted all users')
  }

  const leaveVoice = () => {
    navigate('/app/teams')
  }

  return (
    <div className="min-h-screen bg-gray-900 text-white">
      {/* Header */}
      <div className="bg-gray-800 border-b border-gray-700 px-6 py-4">
        <div className="flex items-center justify-between">
          <div>
            <h1 className="text-2xl font-bold">ğŸ¤ Unified Voice Session</h1>
            <p className="text-gray-400">
              Session: <code className="bg-gray-700 px-2 py-1 rounded text-xs">{VOICE_SESSION_ID}</code>
            </p>
            <p className="text-green-400 text-sm">
              ğŸŸ¢ {participants.length} user{participants.length !== 1 ? 's' : ''} connected
            </p>
          </div>
          <button
            onClick={leaveVoice}
            className="px-4 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700"
          >
            â† Back to Teams
          </button>
        </div>
      </div>

      {/* Main Content */}
      <div className="p-6 max-w-4xl mx-auto">
        
        {/* Session Info */}
        <div className="bg-blue-900/20 border border-blue-700 rounded-lg p-6 mb-6">
          <div className="text-center">
            <div className="text-4xl mb-3">ğŸŒ</div>
            <h2 className="text-xl font-bold text-blue-300 mb-2">
              UNIFIED Voice Session
            </h2>
            <p className="text-blue-200 mb-3">
              Everyone automatically joins this EXACT SAME session
            </p>
            <div className="bg-blue-800/50 rounded p-3">
              <div className="text-sm text-blue-200">
                <div>Session ID: <code>{VOICE_SESSION_ID}</code></div>
                <div>Your User ID: <code className="text-xs">{user?.id}</code></div>
                <div>Connected Users: <span className="text-green-400">{participants.length}</span></div>
              </div>
            </div>
          </div>
        </div>

        {/* Voice Controls */}
        <div className="bg-gray-800 rounded-lg p-6 mb-6">
          <div className="text-center">
            <h3 className="text-lg font-semibold mb-4">Voice Controls</h3>
            
            {/* Audio Status */}
            {audioError ? (
              <div className="mb-4 p-3 bg-red-900/30 border border-red-600 rounded-lg">
                <div className="text-red-300 text-sm">
                  âš ï¸ {audioError}
                </div>
                <button
                  onClick={initializeAudio}
                  className="mt-2 px-3 py-1 bg-red-600 hover:bg-red-700 rounded text-sm"
                >
                  Retry Audio Setup
                </button>
              </div>
            ) : isAudioEnabled ? (
              <div className="mb-4 p-3 bg-green-900/30 border border-green-600 rounded-lg">
                <div className="text-green-300 text-sm flex items-center justify-center gap-2">
                  <div className="w-2 h-2 bg-green-400 rounded-full animate-pulse"></div>
                  ğŸµ Audio enabled - You can hear and be heard
                </div>
              </div>
            ) : (
              <div className="mb-4 p-3 bg-yellow-900/30 border border-yellow-600 rounded-lg">
                <div className="text-yellow-300 text-sm">
                  ğŸ”„ Setting up audio...
                </div>
              </div>
            )}
            
            <div className="flex items-center justify-center gap-6">
              <button
                onClick={toggleMute}
                disabled={!isAudioEnabled}
                className={`w-20 h-20 rounded-full text-3xl transition-all shadow-lg ${
                  !isAudioEnabled
                    ? 'bg-gray-600 cursor-not-allowed opacity-50'
                    : isMuted 
                    ? 'bg-red-600 hover:bg-red-700 shadow-red-500/30' 
                    : 'bg-green-600 hover:bg-green-700 shadow-green-500/30'
                }`}
              >
                {!isAudioEnabled ? 'ğŸ”‡' : isMuted ? 'ğŸ”‡' : 'ğŸ¤'}
              </button>
              <div className="text-center">
                <div className="text-lg font-medium">
                  {!isAudioEnabled 
                    ? 'Audio Disabled' 
                    : isMuted 
                    ? 'You are MUTED' 
                    : 'You are SPEAKING'
                  }
                </div>
                <div className="text-sm text-gray-400">
                  {!isAudioEnabled 
                    ? 'Enable microphone to join voice chat'
                    : `Click microphone to ${isMuted ? 'unmute' : 'mute'}`
                  }
                </div>
                {isAudioEnabled && (
                  <div className="text-xs text-gray-500 mt-1">
                    ğŸ”Š WebRTC Audio Active
                  </div>
                )}
              </div>
            </div>
          </div>
        </div>

        {/* Currently Speaking Users - Discord Style */}
        <div className="bg-gray-800 rounded-lg p-6 mb-6">
          <h3 className="text-lg font-semibold mb-4 flex items-center gap-2">
            ğŸ¤ Currently Speaking
          </h3>
          
          <div className="flex flex-wrap gap-4 justify-center min-h-[80px] items-center">
            {participants.filter(p => !p.is_muted && speakingUsers.has(p.user_id)).length === 0 ? (
              <div className="text-center text-gray-400">
                <div className="text-2xl mb-2">ğŸ”‡</div>
                <p className="text-sm">No one is speaking</p>
                <p className="text-xs text-gray-500 mt-1">
                  {participants.filter(p => !p.is_muted).length} users unmuted
                </p>
              </div>
            ) : (
              participants
                .filter(participant => !participant.is_muted && speakingUsers.has(participant.user_id))
                .map((participant, index) => (
                  <div
                    key={participant.user_id || index}
                    className="flex flex-col items-center gap-2 relative"
                  >
                    {/* Speaking User Avatar with Discord-like Animation */}
                    <div className="relative">
                      <div 
                        className={`w-16 h-16 rounded-full flex items-center justify-center text-xl font-bold transition-all duration-300 ${
                          participant.user_id === user?.id 
                            ? 'bg-blue-600 text-white' 
                            : 'bg-green-600 text-white'
                        }`}
                      >
                        {participant.user_name?.charAt(0) || participant.user_email?.charAt(0) || '?'}
                      </div>
                      
                      {/* Discord-style Speaking Ring Animation */}
                      <div className="absolute inset-0 rounded-full border-4 border-green-400 animate-pulse opacity-75"></div>
                      <div className="absolute inset-0 rounded-full border-2 border-green-300 animate-ping opacity-50"></div>
                      
                      {/* Speaking Indicator */}
                      <div className="absolute -bottom-1 -right-1 w-6 h-6 bg-green-500 rounded-full flex items-center justify-center animate-pulse">
                        <div className="w-3 h-3 bg-white rounded-full"></div>
                      </div>
                    </div>
                    
                    {/* User Name */}
                    <div className="text-center">
                      <p className="text-sm font-medium text-white">
                        {participant.user_name || 'Unknown'}
                        {participant.user_id === user?.id && ' (You)'}
                      </p>
                      <div className="flex items-center gap-1 justify-center">
                        <div className="w-2 h-2 bg-green-400 rounded-full animate-pulse"></div>
                        <span className="text-xs text-green-400">Speaking</span>
                      </div>
                    </div>
                  </div>
                ))
            )}
          </div>
          
          {/* Speaking Stats */}
          <div className="mt-4 pt-4 border-t border-gray-700">
            <div className="flex justify-center gap-6 text-sm text-gray-400">
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-green-500 rounded-full animate-pulse"></div>
                <span>{participants.filter(p => !p.is_muted && speakingUsers.has(p.user_id)).length} Speaking</span>
              </div>
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-yellow-500 rounded-full"></div>
                <span>{participants.filter(p => !p.is_muted && !speakingUsers.has(p.user_id)).length} Listening</span>
              </div>
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-red-500 rounded-full"></div>
                <span>{participants.filter(p => p.is_muted).length} Muted</span>
              </div>
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-blue-500 rounded-full"></div>
                <span>{participants.length} Total</span>
              </div>
            </div>
          </div>
        </div>

        {/* ALL Users in SAME Session */}
        <div className="bg-gray-800 rounded-lg p-6">
          <div className="flex items-center justify-between mb-4">
            <h3 className="text-lg font-semibold flex items-center gap-2">
              ğŸ‘¥ All Users in Unified Session ({participants.length})
            </h3>
            
            {/* Bulk Mute Controls */}
            <div className="flex items-center gap-2">
              <button
                onClick={muteAllUsers}
                className="px-3 py-1 bg-red-600 hover:bg-red-700 rounded-lg text-sm font-medium transition-colors flex items-center gap-1"
              >
                ğŸ”‡ Mute All
              </button>
              <button
                onClick={unmuteAllUsers}
                className="px-3 py-1 bg-green-600 hover:bg-green-700 rounded-lg text-sm font-medium transition-colors flex items-center gap-1"
              >
                ğŸ”Š Unmute All
              </button>
            </div>
          </div>
          
          {participants.length === 0 ? (
            <div className="text-center py-8 text-gray-400">
              <div className="text-4xl mb-2">â³</div>
              <p>Connecting to unified session...</p>
              <p className="text-sm">Other users will appear here</p>
            </div>
          ) : (
            <div className="grid gap-4">
              {participants.map((participant, index) => (
                <div
                  key={participant.user_id || index}
                  className={`p-4 rounded-lg border flex items-center gap-4 transition-all ${
                    participant.user_id === user?.id
                      ? 'bg-blue-900/30 border-blue-600 ring-2 ring-blue-500/20'
                      : 'bg-gray-700/50 border-gray-600'
                  }`}
                >
                  <div className={`w-14 h-14 rounded-full flex items-center justify-center text-xl font-bold ${
                    participant.user_id === user?.id ? 'bg-blue-600' : 'bg-gray-600'
                  }`}>
                    {participant.user_name?.charAt(0) || participant.user_email?.charAt(0) || '?'}
                  </div>
                  
                  <div className="flex-1">
                    <h4 className="font-medium text-lg">
                      {participant.user_name || 'Unknown User'}
                      {participant.user_id === user?.id && ' (YOU)'}
                    </h4>
                    <p className="text-sm text-gray-400">
                      {participant.user_email}
                    </p>
                    <p className="text-xs text-gray-500">
                      Session: {participant.session_id}
                    </p>
                    <p className="text-xs text-gray-500">
                      Joined: {new Date(participant.joined_at).toLocaleTimeString()}
                    </p>
                  </div>
                  
                  <div className="flex flex-col items-end gap-2">
                    {/* Mute Status */}
                    <div className="flex items-center gap-2">
                      {participant.is_muted ? (
                        <span className="px-3 py-1 bg-red-600 rounded-full text-sm font-medium">
                          ğŸ”‡ MUTED
                        </span>
                      ) : (
                        <span className="px-3 py-1 bg-green-600 rounded-full text-sm font-medium">
                          {speakingUsers.has(participant.user_id) ? 'ğŸ¤ SPEAKING' : 'ğŸ§ LISTENING'}
                        </span>
                      )}
                      
                      {/* Individual Mute/Unmute Button */}
                      <button
                        onClick={() => toggleUserMute(participant.user_id, participant.is_muted)}
                        className={`px-3 py-1 rounded-lg text-xs font-medium transition-colors ${
                          participant.is_muted
                            ? 'bg-green-600 hover:bg-green-700 text-white'
                            : 'bg-red-600 hover:bg-red-700 text-white'
                        }`}
                        title={participant.is_muted ? 'Unmute user' : 'Mute user'}
                      >
                        {participant.is_muted ? 'ğŸ”Š Unmute' : 'ğŸ”‡ Mute'}
                      </button>
                    </div>
                    
                    {/* Online Status */}
                    <div className="flex items-center gap-1">
                      <div className="w-2 h-2 bg-green-500 rounded-full animate-pulse"></div>
                      <span className="text-xs text-green-400">Online</span>
                    </div>
                    
                    {/* Speaking Indicator */}
                    {!participant.is_muted && speakingUsers.has(participant.user_id) && (
                      <div className="flex items-center gap-1">
                        <div className="w-2 h-2 bg-green-400 rounded-full animate-pulse"></div>
                        <span className="text-xs text-green-400">Speaking Now</span>
                      </div>
                    )}
                  </div>
                </div>
              ))}
            </div>
          )}
        </div>

      </div>
    </div>
  )
}
